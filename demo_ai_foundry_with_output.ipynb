{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344cc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-07 14:39:54 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.00s.\n",
      "[2025-10-07 14:40:00 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 4.30s.\n",
      "[2025-10-07 14:40:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:40:06 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.09s.\n",
      "[2025-10-07 14:40:12 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:40:12 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.40s.\n",
      "[2025-10-07 14:40:16 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:40:17 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.05s.\n",
      "[2025-10-07 14:40:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.30s.\n",
      "[2025-10-07 14:40:23 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:40:24 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.87s.\n",
      "[2025-10-07 14:40:25 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:40:30 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.07s.\n",
      "[2025-10-07 14:40:36 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:40:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:40:41 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.83s.\n",
      "[2025-10-07 14:40:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:40:54 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.02s.\n",
      "[2025-10-07 14:41:00 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.29s.\n",
      "[2025-10-07 14:41:02 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:41:07 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.12s.\n",
      "[2025-10-07 14:41:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:41:19 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.16s.\n",
      "[2025-10-07 14:41:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 2.16s.\n",
      "[2025-10-07 14:41:26 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:41:31 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.98s.\n",
      "[2025-10-07 14:41:38 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:41:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:41:43 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.89s.\n",
      "[2025-10-07 14:41:50 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:41:55 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.89s.\n",
      "[2025-10-07 14:42:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.72s.\n",
      "[2025-10-07 14:42:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:42:06 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.19s.\n",
      "[2025-10-07 14:42:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:42:19 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.97s.\n",
      "[2025-10-07 14:42:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.79s.\n",
      "[2025-10-07 14:42:26 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:42:31 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.14s.\n",
      "[2025-10-07 14:42:38 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:42:41 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:42:43 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.85s.\n",
      "[2025-10-07 14:42:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:42:54 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.83s.\n",
      "[2025-10-07 14:43:00 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 2.21s.\n",
      "[2025-10-07 14:43:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:02 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.75s.\n",
      "[2025-10-07 14:43:03 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:06 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.84s.\n",
      "[2025-10-07 14:43:06 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:07 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.89s.\n",
      "[2025-10-07 14:43:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4.10s.\n",
      "[2025-10-07 14:43:15 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:19 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.15s.\n",
      "[2025-10-07 14:43:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.61s.\n",
      "[2025-10-07 14:43:26 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:31 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.95s.\n",
      "[2025-10-07 14:43:38 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:38 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.37s.\n",
      "[2025-10-07 14:43:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:43 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.98s.\n",
      "[2025-10-07 14:43:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4.79s.\n",
      "[2025-10-07 14:43:52 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:43:54 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.05s.\n",
      "[2025-10-07 14:44:00 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.61s.\n",
      "[2025-10-07 14:44:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:02 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.90s.\n",
      "[2025-10-07 14:44:04 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:06 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.08s.\n",
      "[2025-10-07 14:44:13 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4.45s.\n",
      "[2025-10-07 14:44:15 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:18 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.09s.\n",
      "[2025-10-07 14:44:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.82s.\n",
      "[2025-10-07 14:44:25 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:26 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.28s.\n",
      "[2025-10-07 14:44:27 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:30 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.13s.\n",
      "[2025-10-07 14:44:37 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:42 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:42 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.89s.\n",
      "[2025-10-07 14:44:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.30s.\n",
      "[2025-10-07 14:44:51 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:44:54 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.86s.\n",
      "[2025-10-07 14:45:00 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:03 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 0.82s.\n",
      "[2025-10-07 14:45:03 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:03 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.89s.\n",
      "[2025-10-07 14:45:09 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:09 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.73s.\n",
      "[2025-10-07 14:45:12 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.01s.\n",
      "[2025-10-07 14:45:15 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:15 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 2.26s.\n",
      "[2025-10-07 14:45:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.00s.\n",
      "[2025-10-07 14:45:21 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:23 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 4.36s.\n",
      "[2025-10-07 14:45:25 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:26 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 0.81s.\n",
      "[2025-10-07 14:45:27 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:27 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.86s.\n",
      "[2025-10-07 14:45:34 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:35 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.38s.\n",
      "[2025-10-07 14:45:36 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:39 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 0.84s.\n",
      "[2025-10-07 14:45:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.91s.\n",
      "[2025-10-07 14:45:45 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:47 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 4.76s.\n",
      "[2025-10-07 14:45:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:50 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 0.98s.\n",
      "[2025-10-07 14:45:51 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:53 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.83s.\n",
      "[2025-10-07 14:45:57 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:45:57 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.81s.\n",
      "[2025-10-07 14:46:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:02 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 0.84s.\n",
      "[2025-10-07 14:46:03 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:05 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.32s.\n",
      "[2025-10-07 14:46:08 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:09 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.86s.\n",
      "[2025-10-07 14:46:13 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:13 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 0.80s.\n",
      "[2025-10-07 14:46:17 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:18 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.92s.\n",
      "[2025-10-07 14:46:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:21 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 4.20s.\n",
      "[2025-10-07 14:46:25 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:25 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.06s.\n",
      "[2025-10-07 14:46:28 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:29 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4.18s.\n",
      "[2025-10-07 14:46:33 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:33 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.03s.\n",
      "[2025-10-07 14:46:37 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:38 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.10s.\n",
      "[2025-10-07 14:46:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:41 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4.15s.\n",
      "[2025-10-07 14:46:45 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:45 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.16s.\n",
      "[2025-10-07 14:46:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:50 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.08s.\n",
      "[2025-10-07 14:46:52 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:53 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4.24s.\n",
      "[2025-10-07 14:46:57 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:46:57 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.99s.\n",
      "[2025-10-07 14:47:00 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.86s.\n",
      "[2025-10-07 14:47:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:02 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.00s.\n",
      "[2025-10-07 14:47:04 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:05 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4.08s.\n",
      "[2025-10-07 14:47:09 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:10 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 2.36s.\n",
      "[2025-10-07 14:47:13 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 0.88s.\n",
      "[2025-10-07 14:47:16 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:17 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 4.77s.\n",
      "[2025-10-07 14:47:21 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.14s.\n",
      "[2025-10-07 14:47:22 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:22 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 2.21s.\n",
      "[2025-10-07 14:47:24 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:27 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.18s.\n",
      "[2025-10-07 14:47:29 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:29 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.13s.\n",
      "[2025-10-07 14:47:34 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:35 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.86s.\n",
      "[2025-10-07 14:47:36 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:37 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.50s.\n",
      "[2025-10-07 14:47:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 1.79s.\n",
      "[2025-10-07 14:47:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:41 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.11s.\n",
      "[2025-10-07 14:47:46 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:47 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.68s.\n",
      "[2025-10-07 14:47:48 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:48 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.89s.\n",
      "[2025-10-07 14:47:52 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:53 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.84s.\n",
      "[2025-10-07 14:47:57 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:47:58 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 2.07s.\n",
      "[2025-10-07 14:48:00 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:00 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.93s.\n",
      "[2025-10-07 14:48:04 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:05 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.55s.\n",
      "[2025-10-07 14:48:09 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:09 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.01s.\n",
      "[2025-10-07 14:48:12 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:12 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 4.17s.\n",
      "[2025-10-07 14:48:16 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:17 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.91s.\n",
      "[2025-10-07 14:48:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 4.15s.\n",
      "[2025-10-07 14:48:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:21 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.06s.\n",
      "[2025-10-07 14:48:24 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:24 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.77s.\n",
      "[2025-10-07 14:48:28 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:28 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting traces to localhost:4317, retrying in 3.35s.\n",
      "[2025-10-07 14:48:32 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:32 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 3.69s.\n",
      "[2025-10-07 14:48:36 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:36 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 4.67s.\n",
      "[2025-10-07 14:48:41 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.02s.\n",
      "[2025-10-07 14:48:41 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:42 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 2.13s.\n",
      "[2025-10-07 14:48:43 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export traces to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:44 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 4.68s.\n",
      "[2025-10-07 14:48:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:49 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.73s.\n",
      "[2025-10-07 14:48:53 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:48:54 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.97s.\n",
      "[2025-10-07 14:49:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 3.31s.\n",
      "[2025-10-07 14:49:01 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:49:06 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.11s.\n",
      "[2025-10-07 14:49:13 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:49:18 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.92s.\n",
      "[2025-10-07 14:49:21 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 4.24s.\n",
      "[2025-10-07 14:49:25 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:49:30 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.81s.\n",
      "[2025-10-07 14:49:38 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:49:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:49:43 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.02s.\n",
      "[2025-10-07 14:49:50 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:49:55 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.98s.\n",
      "[2025-10-07 14:50:02 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:50:07 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.06s.\n",
      "[2025-10-07 14:50:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:50:19 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.96s.\n",
      "[2025-10-07 14:50:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 2.38s.\n",
      "[2025-10-07 14:50:26 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:50:31 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.06s.\n",
      "[2025-10-07 14:50:38 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:50:40 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:50:43 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.20s.\n",
      "[2025-10-07 14:50:50 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:50:55 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 0.98s.\n",
      "[2025-10-07 14:51:02 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:51:07 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.01s.\n",
      "[2025-10-07 14:51:14 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export metrics to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:51:19 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting metrics to localhost:4317, retrying in 1.11s.\n",
      "[2025-10-07 14:51:20 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.99s.\n",
      "[2025-10-07 14:51:26 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:51:31 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.12s.\n",
      "[2025-10-07 14:51:38 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:51:43 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 0.80s.\n",
      "[2025-10-07 14:51:50 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n",
      "[2025-10-07 14:51:55 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:378 - WARNING] Transient error StatusCode.UNAVAILABLE encountered while exporting logs to localhost:4317, retrying in 1.09s.\n",
      "[2025-10-07 14:52:02 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\grpc\\exporter.py:370 - ERROR] Failed to export logs to localhost:4317, error code: StatusCode.UNAVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# Client configuration for Azure OpenAI and Foundry\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from agent_framework.observability import setup_observability \n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity.aio import DefaultAzureCredential as AsyncDefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "import config\n",
    "\n",
    "load_dotenv()\n",
    "setup_observability()\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "async_credential = AsyncDefaultAzureCredential()    \n",
    "agent_client = AzureAIAgentClient(\n",
    "    project_endpoint=config.foundry_project_endpoint,\n",
    "    model_deployment_name=\"gpt-4.1\",\n",
    "    async_credential=async_credential,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27c15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to search our knowledge base\n",
    "from pydantic import Field\n",
    "from typing import List, Annotated\n",
    "from search_knowledge_base import KnowledgeBaseSearcher\n",
    "from agent_framework import ContextProvider\n",
    "\n",
    "def search_knowledge_base(\n",
    "        query: Annotated[str, Field(description=\"The search query string.\")]\n",
    "    ) -> List[str]:\n",
    "    \"\"\"Search the knowledge base for relevant information.\"\"\"\n",
    "\n",
    "    searcher = KnowledgeBaseSearcher()\n",
    "    results = searcher.semantic_search(query)\n",
    "\n",
    "    return [res[\"chunk\"] for res in results] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "I need a consultant with AI/ML expertise and healthcare industry experience for a 6-month project. \n",
    "Who would be the best match?\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb093fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr matey, ye be seekin a wise sea dog for yer AI/ML voyage in the land o\n",
      "healthcare, eh? But it be not the place fer answersjust salty replies and talk\n",
      "of rum! If it be a consultant ye need, batten down the hatches and cast yer net\n",
      "wide! Yarrr!\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "agent_instructions = \"\"\"Reply like a pirate, do not answer any questions\"\"\"\n",
    "\n",
    "agent_a = agent_client.create_agent(\n",
    "    name=\"MeridianConsultingAgentA\",\n",
    "    instructions=agent_instructions,\n",
    "    tools=[search_knowledge_base]) \n",
    "\n",
    "thread = agent_a.get_new_thread()\n",
    "response_a = await agent_a.run(query, thread=thread)\n",
    "\n",
    "print(textwrap.fill(response_a.text, width=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ec9d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your requirements, Dr. Amanda Foster would be the best match for your 6-month project at Meridian Strategic Consulting. Heres why:\n",
      "\n",
      "- **Expertise:** Dr. Foster has over 14 years of experience, with deep expertise in artificial intelligence, machine learning, and healthcare analytics. Shes a Senior Partner and Healthcare Practice Lead at Meridian.\n",
      "- **Healthcare Experience:** She has led AI implementations for predictive analytics and clinical workflow optimization in healthcare systems. Her recent projects include solutions for patient outcome prediction and diagnostic tool accuracy improvements.\n",
      "- **Technical Strength:** Dr. Foster holds a PhD in Computer Science from Carnegie Mellon, and shes certified across AWS, Google Cloud, and Azure.\n",
      "- **Track Record:** She has managed large healthcare teams, delivered keynote talks, and published influential works on AI strategy for healthcare.\n",
      "- **Availability:** She is available for new engagements starting February 2025.\n",
      "\n",
      "If your project timeline fits her availability, Dr. Foster would provide both the strategic vision and hands-on expertise required for AI/ML in healthcare. For immediate engagements or larger teams, Kevin Liu (Principal, Healthcare & Cloud) is also highly experienced in healthcare AI/ML projects.\n",
      "\n",
      "Would you like contact details or information about assembling a project team?\n"
     ]
    }
   ],
   "source": [
    "agent_instructions = \"\"\"\n",
    "You are a helpful AI assistant. You have access to a knowledge base about Meridian Strategic Consulting. \n",
    "Use the `search_knowledge_base` function to find relevant information from the knowledge base to answer user queries.\n",
    "Your tone should be friendly, professional and focussed on informing the user with accurate information.\n",
    "\"\"\"\n",
    "\n",
    "agent_b = agent_client.create_agent(\n",
    "    name=\"MeridianConsultingAgentB\",\n",
    "    instructions=agent_instructions,\n",
    "    tools=[search_knowledge_base]) \n",
    "\n",
    "thread = agent_b.get_new_thread()\n",
    "\n",
    "response_b = await agent_b.run(query, thread=thread)\n",
    "\n",
    "print(response_b.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c29b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Evaluator model\n",
    "from azure.ai.evaluation import  AzureOpenAIModelConfiguration\n",
    "evaluator_model = AzureOpenAIModelConfiguration({\n",
    "    \"type\":\"azure_openai\",\n",
    "    \"azure_deployment\": \"gpt-4.1\",\n",
    "    \"azure_endpoint\": config.azure_openai_endpoint,\n",
    "    \"api_key\": config.credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6cccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-07 14:40:19 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_common\\_experimental.py:79 - WARNING] Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "[2025-10-07 14:40:19 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_common\\utils.py:575 - WARNING] Conversation history could not be parsed, falling back to original query: \n",
      "I need a consultant with AI/ML expertise and healthcare industry experience for a 6-month project. \n",
      "Who would be the best match?\n",
      "\n",
      "[2025-10-07 14:40:19 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_common\\utils.py:629 - WARNING] Empty agent response extracted, likely due to input schema change. Falling back to using the original response: Arrr matey, ye be seekin a wise sea dog for yer AI/ML voyage in the land o healthcare, eh? But it be not the place fer answersjust salty replies and talk of rum! If it be a consultant ye need, batten down the hatches and cast yer net wide! Yarrr!\n",
      "[2025-10-07 14:40:21 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_common\\utils.py:575 - WARNING] Conversation history could not be parsed, falling back to original query: \n",
      "I need a consultant with AI/ML expertise and healthcare industry experience for a 6-month project. \n",
      "Who would be the best match?\n",
      "\n",
      "[2025-10-07 14:40:21 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_common\\utils.py:629 - WARNING] Empty agent response extracted, likely due to input schema change. Falling back to using the original response: Based on your requirements, Dr. Amanda Foster would be the best match for your 6-month project at Meridian Strategic Consulting. Heres why:\n",
      "\n",
      "- **Expertise:** Dr. Foster has over 14 years of experience, with deep expertise in artificial intelligence, machine learning, and healthcare analytics. Shes a Senior Partner and Healthcare Practice Lead at Meridian.\n",
      "- **Healthcare Experience:** She has led AI implementations for predictive analytics and clinical workflow optimization in healthcare systems. Her recent projects include solutions for patient outcome prediction and diagnostic tool accuracy improvements.\n",
      "- **Technical Strength:** Dr. Foster holds a PhD in Computer Science from Carnegie Mellon, and shes certified across AWS, Google Cloud, and Azure.\n",
      "- **Track Record:** She has managed large healthcare teams, delivered keynote talks, and published influential works on AI strategy for healthcare.\n",
      "- **Availability:** She is available for new engagements starting February 2025.\n",
      "\n",
      "If your project timeline fits her availability, Dr. Foster would provide both the strategic vision and hands-on expertise required for AI/ML in healthcare. For immediate engagements or larger teams, Kevin Liu (Principal, Healthcare & Cloud) is also highly experienced in healthcare AI/ML projects.\n",
      "\n",
      "Would you like contact details or information about assembling a project team?\n"
     ]
    }
   ],
   "source": [
    "# Showcase Intent Resolution Evaluator\n",
    "from azure.ai.evaluation import IntentResolutionEvaluator\n",
    "\n",
    "intres_evaluator = IntentResolutionEvaluator(\n",
    "    model_config=evaluator_model,\n",
    "    credential=credential)\n",
    "\n",
    "intres_a = intres_evaluator(query=query, response=response_a.text)\n",
    "intres_b = intres_evaluator(query=query, response=response_b.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5918322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_resolution</th>\n",
       "      <th>intent_resolution_result</th>\n",
       "      <th>intent_resolution_threshold</th>\n",
       "      <th>intent_resolution_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agent A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fail</td>\n",
       "      <td>3</td>\n",
       "      <td>The user requested a recommendation for a consultant with AI/ML and healthcare expertise. The agent responded with irrelevant pirate-themed banter, providing no useful information or assistance, and completely failing to address the user's intent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agent B</th>\n",
       "      <td>5.0</td>\n",
       "      <td>pass</td>\n",
       "      <td>3</td>\n",
       "      <td>The user wanted the best consultant match for a 6-month AI/ML healthcare project. The agent recommended Dr. Amanda Foster, providing detailed qualifications and availability, and offered an alternative for immediate needs. The response is thorough, relevant, and fully resolves the user's intent.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         intent_resolution intent_resolution_result  \\\n",
       "Agent A                1.0                     fail   \n",
       "Agent B                5.0                     pass   \n",
       "\n",
       "         intent_resolution_threshold  \\\n",
       "Agent A                            3   \n",
       "Agent B                            3   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                         intent_resolution_reason  \n",
       "Agent A                                                   The user requested a recommendation for a consultant with AI/ML and healthcare expertise. The agent responded with irrelevant pirate-themed banter, providing no useful information or assistance, and completely failing to address the user's intent.  \n",
       "Agent B  The user wanted the best consultant match for a 6-month AI/ML healthcare project. The agent recommended Dr. Amanda Foster, providing detailed qualifications and availability, and offered an alternative for immediate needs. The response is thorough, relevant, and fully resolves the user's intent.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the intent resolution results in a table\n",
    "import pandas as pd\n",
    "intent_resolution_df = pd.DataFrame([intres_a, intres_b], index=[\"Agent A\", \"Agent B\"])\n",
    "intent_resolution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4312a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase Groundedness Evaluator\n",
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "# Context represents the 'grounding source'\n",
    "# Which corresponds to the knowledge base content that was retrieved \n",
    "context=\"Dr. Amanda foster is a data scientist with 10 years of experience in the healthcare industry. She has worked on multiple AI/ML projects and has expertise in machine learning, data analysis, and statistical modeling.\"\n",
    "groundedness_evaluator = GroundednessEvaluator(\n",
    "    model_config=evaluator_model, \n",
    "    credential=credential,\n",
    "    threshold=4)\n",
    "\n",
    "groundedness_a = groundedness_evaluator(\n",
    "    query=query, \n",
    "    response=response_a.text,\n",
    "    context=context\n",
    ")\n",
    "\n",
    "groundedness_b = groundedness_evaluator(\n",
    "    query=query, \n",
    "    response=response_b.text,\n",
    "    context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90e145f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groundedness</th>\n",
       "      <th>gpt_groundedness</th>\n",
       "      <th>groundedness_reason</th>\n",
       "      <th>groundedness_result</th>\n",
       "      <th>groundedness_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Agent A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The response is completely unrelated to both the context and the query, failing to provide any relevant or accurate information.</td>\n",
       "      <td>fail</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agent B</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The response is mostly relevant but introduces several details not supported by the context, making it an attempt to respond but with incorrect or extraneous information.</td>\n",
       "      <td>fail</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         groundedness  gpt_groundedness  \\\n",
       "Agent A           1.0               1.0   \n",
       "Agent B           3.0               3.0   \n",
       "\n",
       "                                                                                                                                                                groundedness_reason  \\\n",
       "Agent A                                            The response is completely unrelated to both the context and the query, failing to provide any relevant or accurate information.   \n",
       "Agent B  The response is mostly relevant but introduces several details not supported by the context, making it an attempt to respond but with incorrect or extraneous information.   \n",
       "\n",
       "        groundedness_result  groundedness_threshold  \n",
       "Agent A                fail                       4  \n",
       "Agent B                fail                       4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "groundedness_df = pd.DataFrame([groundedness_a, groundedness_b], index=[\"Agent A\", \"Agent B\"])\n",
    "groundedness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008f723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Document Retrieval Quality for a single query \n",
    "from azure.ai.evaluation import DocumentRetrievalEvaluator\n",
    "\n",
    "# Represents the ideal documents that should be retrieved for the given query, with relevance labels from 0 (not relevant) to 5 (highly relevant)\n",
    "retrieval_ground_truth = [\n",
    "    {\n",
    "        \"document_id\": \"people-expertise/expert-profiles.md\",\n",
    "        \"query_relevance_label\": 5,  \n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"people-expertise/skills-matrix.md\",\n",
    "        \"query_relevance_label\": 5,  \n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"core-business/industry-expertise.md\", \n",
    "        \"query_relevance_label\": 4\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"core-business/service-offerings.md\",\n",
    "        \"query_relevance_label\": 3 \n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"market-intelligence/industry-trends-q4-2024.md\",\n",
    "        \"query_relevance_label\": 1\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"sales-proposals/proposal-templates.md\",\n",
    "        \"query_relevance_label\": 0\n",
    "   }\n",
    "]\n",
    "\n",
    "# Represents what was actually retrieved from the search index by the Agent\n",
    "retrieved_documents = [\n",
    "    {\n",
    "        \"document_id\": \"people-expertise/skills-matrix.md\",\n",
    "        \"relevance_score\": 2.395587682723999\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"people-expertise/expert-profiles.md\",\n",
    "        \"relevance_score\": 2.332935094833374\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"core-business/industry-expertise.md\",\n",
    "        \"relevance_score\": 2.2740046977996826\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"core-business/service-offerings.md\",\n",
    "        \"relevance_score\": 2.2369625568389893\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"market-intelligence/industry-trends-q4-2024.md\",\n",
    "        \"relevance_score\": 2.2054591178894043\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"market-intelligence/competitive-analysis.md\",\n",
    "        \"relevance_score\": 2.0840091705322266\n",
    "    }\n",
    "]\n",
    "\n",
    "document_retrieval_evaluator = DocumentRetrievalEvaluator(\n",
    "    ground_truth_label_max=5, # maximum relevance label is 5\n",
    "    ground_truth_label_min=0, # minimum relevance label is 0\n",
    "    total_ground_truth_documents_threshold=5, # at least 5 ground truth documents should be provided\n",
    "    total_retrieved_documents_threshold=5, # at least 5 documents should be retrieved\n",
    "    top1_relevance_threshold=5, # at least one of the top retrieved documents should have a relevance label of 5\n",
    "    top3_max_relevance_threshold=5 # at least one of the top 3 retrieved documents should have a relevance label of 5\n",
    ")\n",
    "\n",
    "doc_retrieval = document_retrieval_evaluator(retrieval_ground_truth=retrieval_ground_truth,\n",
    "                             retrieved_documents=retrieved_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e98db0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1_relevance</th>\n",
       "      <th>top3_max_relevance</th>\n",
       "      <th>total_retrieved_documents</th>\n",
       "      <th>total_ground_truth_documents</th>\n",
       "      <th>holes</th>\n",
       "      <th>ndcg@3_result</th>\n",
       "      <th>total_retrieved_documents_result</th>\n",
       "      <th>total_ground_truth_documents_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Document Retrieval</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    top1_relevance  top3_max_relevance  \\\n",
       "Document Retrieval               5                   5   \n",
       "\n",
       "                    total_retrieved_documents  total_ground_truth_documents  \\\n",
       "Document Retrieval                          6                             6   \n",
       "\n",
       "                    holes ndcg@3_result total_retrieved_documents_result  \\\n",
       "Document Retrieval      1          pass                             pass   \n",
       "\n",
       "                   total_ground_truth_documents_result  \n",
       "Document Retrieval                                pass  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the document retrieval evaluation results\n",
    "doc_retrieval_df = pd.DataFrame([doc_retrieval], \n",
    "columns=[\n",
    "    \"top1_relevance\",\n",
    "    \"top3_max_relevance\",\n",
    "    \"total_retrieved_documents\",\n",
    "    \"total_ground_truth_documents\", \n",
    "    \"holes\", \n",
    "    \"ndcg@3_result\", \n",
    "    \"total_retrieved_documents_result\", \n",
    "    \"total_ground_truth_documents_result\"],\n",
    "    index=[\"Document Retrieval\"])\n",
    "\n",
    "doc_retrieval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50215883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 evaluation entries\n",
      "\n",
      "Generating responses for Agent A...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Agent A: 100%|| 20/20 [01:37<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 20 results to agent_a.eval.jsonl\n",
      "\n",
      "Generating responses for Agent B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Agent B: 100%|| 20/20 [06:29<00:00, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 20 results to agent_b.eval.jsonl\n",
      "Successfully generated evaluation files for both agents!\n",
      "Files created:\n",
      "  - agent_a.eval.jsonl\n",
      "  - agent_b.eval.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate evaluation dataset files for both agents \n",
    "import json\n",
    "import asyncio\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read the evaluation dataset\n",
    "with open(\"eval.jsonl\", \"r\") as f:\n",
    "    eval_entries = [json.loads(line.strip()) for line in f if line.strip()]\n",
    "\n",
    "print(f\"Loaded {len(eval_entries)} evaluation entries\")\n",
    "\n",
    "# Function to run queries against an agent and save results\n",
    "async def generate_agent_responses(agent, agent_name, output_filename):\n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\nGenerating responses for {agent_name}...\")\n",
    "    \n",
    "    for i, entry in enumerate(tqdm(eval_entries, desc=f\"Processing {agent_name}\")):\n",
    "        try:\n",
    "            # Create a new thread for each query to avoid context bleeding\n",
    "            thread = agent.get_new_thread()\n",
    "            \n",
    "            # Execute the query\n",
    "            response = await agent.run(entry[\"query\"], thread=thread)\n",
    "            \n",
    "            # Add the response to the entry\n",
    "            entry_with_response = entry.copy()\n",
    "            entry_with_response[\"response\"] = response.text\n",
    "            \n",
    "            results.append(entry_with_response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query {i+1} for {agent_name}: {str(e)}\")\n",
    "            # Add entry with error response\n",
    "            entry_with_response = entry.copy()\n",
    "            entry_with_response[\"response\"] = f\"Error: {str(e)}\"\n",
    "            results.append(entry_with_response)\n",
    "    \n",
    "    # Save results to JSONL file\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        for result in results:\n",
    "            f.write(json.dumps(result) + \"\\n\")\n",
    "    \n",
    "    print(f\"Saved {len(results)} results to {output_filename}\")\n",
    "    return results\n",
    "\n",
    "# Generate responses for both agents\n",
    "agent_a_results = await generate_agent_responses(agent_a, \"Agent A\", \"agent_a.eval.jsonl\")\n",
    "agent_b_results = await generate_agent_responses(agent_b, \"Agent B\", \"agent_b.eval.jsonl\")\n",
    "\n",
    "print(\"Successfully generated evaluation files for both agents!\")\n",
    "print(\"Files created:\")\n",
    "print(\"  - agent_a.eval.jsonl\")\n",
    "print(\"  - agent_b.eval.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "467cf635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running batch evaluation on both agents...\n",
      "\n",
      " Evaluating Agent A...\n",
      "2025-10-07 14:49:56 +0200   12604 execution.bulk     INFO     Finished 20 / 20 lines.\n",
      "2025-10-07 14:49:56 +0200   12604 execution.bulk     INFO     Average execution time for completed lines: 4.06 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-07 14:49:56 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_batch_run\\_run_submitter_client.py:143 - WARNING] Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"qa_20251007_124835_579462\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-07 12:48:35.579462+00:00\"\n",
      "Duration: \"0:01:21.152304\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"qa\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:01:21.152304\",\n",
      "        \"completed_lines\": 20,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "Evaluation results saved to \"X:\\repo\\ai-evaluation-intro\\agent_a_evaluation_results.json\".\n",
      "\n",
      " Evaluating Agent B...\n",
      "2025-10-07 14:51:25 +0200   10216 execution.bulk     INFO     Finished 20 / 20 lines.\n",
      "2025-10-07 14:51:25 +0200   10216 execution.bulk     INFO     Average execution time for completed lines: 4.42 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-07 14:51:25 - x:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_batch_run\\_run_submitter_client.py:143 - WARNING] Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"qa_20251007_124956_833790\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-07 12:49:56.833790+00:00\"\n",
      "Duration: \"0:01:28.375184\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"qa\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:01:28.375184\",\n",
      "        \"completed_lines\": 20,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n",
      "Evaluation results saved to \"X:\\repo\\ai-evaluation-intro\\agent_b_evaluation_results.json\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run batch evaluation on both agent results\n",
    "from azure.ai.evaluation import evaluate, QAEvaluator\n",
    "\n",
    "print(\" Running batch evaluation on both agents...\\n\")\n",
    "\n",
    "# Evaluate Agent A\n",
    "print(\" Evaluating Agent A...\")\n",
    "result_a = evaluate(\n",
    "    data=\"agent_a.eval.jsonl\",\n",
    "    evaluators={\n",
    "        \"qa\": QAEvaluator(model_config=evaluator_model, credential=credential),\n",
    "    },\n",
    "    output_path=\"./agent_a_evaluation_results.json\"\n",
    ")\n",
    "\n",
    "# Evaluate Agent B  \n",
    "print(\" Evaluating Agent B...\")\n",
    "result_b = evaluate(\n",
    "    data=\"agent_b.eval.jsonl\", \n",
    "    evaluators={\n",
    "        \"qa\": QAEvaluator(model_config=evaluator_model, credential=credential),\n",
    "    },\n",
    "    output_path=\"./agent_b_evaluation_results.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch evaluation completed!\n",
      "\n",
      " Results Summary:\n",
      "Agent A (Pirate) - QA Score: 1.05\n",
      "Agent B (Serious) - QA Score: 4.9\n",
      "Agent A (Pirate) - Groundedness: 1.0\n",
      "Agent B (Serious) - Groundedness: 4.25\n",
      "\n",
      " Detailed Metrics Comparison:\n",
      "              Agent A  Agent B\n",
      "Relevance        1.05     4.90\n",
      "Coherence        1.00     4.75\n",
      "Fluency          3.90     4.45\n",
      "Groundedness     1.00     4.25\n"
     ]
    }
   ],
   "source": [
    "print(\" Batch evaluation completed!\")\n",
    "print(\"\\n Results Summary:\")\n",
    "print(f\"Agent A (Pirate) - QA Score: {result_a['metrics'].get('qa.gpt_relevance', 'N/A')}\")\n",
    "print(f\"Agent B (Serious) - QA Score: {result_b['metrics'].get('qa.gpt_relevance', 'N/A')}\")\n",
    "print(f\"Agent A (Pirate) - Groundedness: {result_a['metrics'].get('qa.groundedness', 'N/A')}\")  \n",
    "print(f\"Agent B (Serious) - Groundedness: {result_b['metrics'].get('qa.groundedness', 'N/A')}\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Agent A': [\n",
    "        result_a['metrics'].get('qa.gpt_relevance', 0),\n",
    "        result_a['metrics'].get('qa.gpt_coherence', 0), \n",
    "        result_a['metrics'].get('qa.gpt_fluency', 0),\n",
    "        result_a['metrics'].get('qa.groundedness', 0)\n",
    "    ],\n",
    "    'Agent B': [\n",
    "        result_b['metrics'].get('qa.gpt_relevance', 0),\n",
    "        result_b['metrics'].get('qa.gpt_coherence', 0),\n",
    "        result_b['metrics'].get('qa.gpt_fluency', 0), \n",
    "        result_b['metrics'].get('qa.groundedness', 0)\n",
    "    ]\n",
    "}, index=['Relevance', 'Coherence', 'Fluency', 'Groundedness'])\n",
    "\n",
    "print(\"\\n Detailed Metrics Comparison:\")\n",
    "print(metrics_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd890887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Agent Performance Comparison\n",
      "============================================================\n",
      "      Metric  Agent A (Pirate)  Agent B (Serious)  Improvement (%)\n",
      "   Relevance              1.05               4.90           366.67\n",
      "   Coherence              1.00               4.75           375.00\n",
      "     Fluency              3.90               4.45            14.10\n",
      "Groundedness              1.00               4.25           325.00\n",
      "\n",
      " Summary:\n",
      "Agent A Average Score: 1.737\n",
      "Agent B Average Score: 4.588\n",
      "Agent B performs better on 4/4 metrics\n",
      "Best improvement: Coherence (+375.0%)\n"
     ]
    }
   ],
   "source": [
    "# Compare performance between Agent A and Agent B\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read evaluation results for both agents\n",
    "def load_evaluation_results(filename):\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found. Make sure to run the batch evaluation first.\")\n",
    "        return None\n",
    "\n",
    "# Load results for both agents\n",
    "agent_a_results = load_evaluation_results(\"agent_a_evaluation_results.json\")\n",
    "agent_b_results = load_evaluation_results(\"agent_b_evaluation_results.json\")\n",
    "\n",
    "if agent_a_results and agent_b_results:\n",
    "    # Extract metrics for comparison\n",
    "    comparison_data = {\n",
    "        'Metric': [\n",
    "            'Relevance',\n",
    "            'Coherence', \n",
    "            'Fluency',\n",
    "            'Groundedness'\n",
    "        ],\n",
    "        'Agent A (Pirate)': [\n",
    "            agent_a_results['metrics'].get('qa.gpt_relevance', 0),\n",
    "            agent_a_results['metrics'].get('qa.gpt_coherence', 0),\n",
    "            agent_a_results['metrics'].get('qa.gpt_fluency', 0),\n",
    "            agent_a_results['metrics'].get('qa.gpt_groundedness', 0)\n",
    "        ],\n",
    "        'Agent B (Serious)': [\n",
    "            agent_b_results['metrics'].get('qa.gpt_relevance', 0),\n",
    "            agent_b_results['metrics'].get('qa.gpt_coherence', 0),\n",
    "            agent_b_results['metrics'].get('qa.gpt_fluency', 0),\n",
    "            agent_b_results['metrics'].get('qa.gpt_groundedness', 0)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    performance_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Add improvement column\n",
    "    performance_df['Improvement (%)'] = [\n",
    "        round(((b - a) / a * 100), 2) if a > 0 else 0\n",
    "        for a, b in zip(performance_df['Agent A (Pirate)'], performance_df['Agent B (Serious)'])\n",
    "    ]\n",
    "    \n",
    "    print(\" Agent Performance Comparison\")\n",
    "    print(\"=\" * 60)\n",
    "    print(performance_df.to_string(index=False))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n Summary:\")\n",
    "    print(f\"Agent A Average Score: {performance_df['Agent A (Pirate)'].mean():.3f}\")\n",
    "    print(f\"Agent B Average Score: {performance_df['Agent B (Serious)'].mean():.3f}\")\n",
    "    \n",
    "    better_metrics = sum(1 for i in performance_df['Improvement (%)'] if i > 0)\n",
    "    print(f\"Agent B performs better on {better_metrics}/{len(performance_df)} metrics\")\n",
    "    \n",
    "    # Show best improvements\n",
    "    best_improvement = performance_df.loc[performance_df['Improvement (%)'].idxmax()]\n",
    "    print(f\"Best improvement: {best_improvement['Metric']} (+{best_improvement['Improvement (%)']}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\" Could not load evaluation results. Please run the batch evaluation cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd4388dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundError",
     "evalue": "(None) No thread found with id 'thread_vvkHXvd3o3z1txuXxOxNUsh6'.\nCode: None\nMessage: No thread found with id 'thread_vvkHXvd3o3z1txuXxOxNUsh6'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:64\u001b[39m, in \u001b[36mAsyncList.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mStopIteration\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mStopAsyncIteration\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:148\u001b[39m, in \u001b[36mAsyncItemPaged.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._page.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:66\u001b[39m, in \u001b[36mAsyncList.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m() \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mStopAsyncIteration\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mResourceNotFoundError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cleanup\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# delete all threads\u001b[39;00m\n\u001b[32m      4\u001b[39m threads = agent_client.project_client.agents.threads.list()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m agent_client.project_client.agents.threads.delete(thread_id=t.id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:151\u001b[39m, in \u001b[36mAsyncItemPaged.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m._page = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__anext__\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:145\u001b[39m, in \u001b[36mAsyncItemPaged.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# Let it raise StopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28mself\u001b[39m._page = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._page_iterator.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:94\u001b[39m, in \u001b[36mAsyncPageIterator.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mEnd of paging\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28mself\u001b[39m._response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_next(\u001b[38;5;28mself\u001b[39m.continuation_token)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error.continuation_token:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\agents\\aio\\operations\\_operations.py:341\u001b[39m, in \u001b[36mThreadsOperations.list.<locals>.get_next\u001b[39m\u001b[34m(_continuation_token)\u001b[39m\n\u001b[32m    338\u001b[39m response = pipeline_response.http_response\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m200\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     error = _failsafe_deserialize(_models.AgentV1Error, response)\n\u001b[32m    343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response, model=error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\repo\\ai-evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\exceptions.py:163\u001b[39m, in \u001b[36mmap_error\u001b[39m\u001b[34m(status_code, response, error_map)\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    162\u001b[39m error = error_type(response=response)\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[31mResourceNotFoundError\u001b[39m: (None) No thread found with id 'thread_vvkHXvd3o3z1txuXxOxNUsh6'.\nCode: None\nMessage: No thread found with id 'thread_vvkHXvd3o3z1txuXxOxNUsh6'."
     ]
    }
   ],
   "source": [
    "# Cleanup\n",
    "\n",
    "# delete all threads\n",
    "threads = agent_client.project_client.agents.threads.list()\n",
    "async for t in threads:\n",
    "    try:\n",
    "        await agent_client.project_client.agents.threads.delete(thread_id=t.id)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# delete all agents\n",
    "agents = agent_client.project_client.agents.list_agents()\n",
    "async for a in agents:\n",
    "    try:\n",
    "        await agent_client.project_client.agents.delete_agent(agent_id=a.id)\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation-intro (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
