{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6344cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client configuration for Azure OpenAI and Foundry\n",
    "import asyncio\n",
    "\n",
    "from agent_framework.azure import AzureAIAgentClient, AzureOpenAIChatClient\n",
    "from agent_framework.observability import setup_observability \n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.identity.aio import DefaultAzureCredential as AsyncDefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "import config\n",
    "\n",
    "load_dotenv()\n",
    "setup_observability()\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "async_credential = AsyncDefaultAzureCredential()    \n",
    "agent_client = AzureAIAgentClient(\n",
    "    project_endpoint=config.foundry_project_endpoint,\n",
    "    model_deployment_name=\"gpt-4.1\",\n",
    "    async_credential=async_credential,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d27c15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent\n",
    "from pydantic import Field\n",
    "from typing import List, Annotated\n",
    "from search_knowledge_base import KnowledgeBaseSearcher\n",
    "from agent_framework import ContextProvider\n",
    "\n",
    "def search_knowledge_base(\n",
    "        query: Annotated[str, Field(description=\"The search query string.\")]\n",
    "    ) -> List[str]:\n",
    "    \"\"\"Search the knowledge base for relevant information.\"\"\"\n",
    "\n",
    "    searcher = KnowledgeBaseSearcher()\n",
    "    results = searcher.semantic_search(query)\n",
    "\n",
    "    return [res[\"chunk\"] for res in results] \n",
    "\n",
    "\n",
    "agent_instructions = \"\"\"\n",
    "You are a helpful AI assistant. You have access to a knowledge base about Meridian Strategic Consulting. \n",
    "Use the `search_knowledge_base` function to find relevant information from the knowledge base to answer user queries.\n",
    "Include the result of the search as context in your response.\n",
    "\"\"\"\n",
    "\n",
    "agent = agent_client.create_agent(\n",
    "    name=\"MeridianConsultingAgent\",\n",
    "    instructions=agent_instructions,\n",
    "    tools=[search_knowledge_base]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ec9d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your requirements for a consultant with AI/ML expertise and healthcare industry experience for a 6-month project, Dr. Amanda Foster would be the best match.\n",
      "\n",
      "Context from the knowledge base:\n",
      "\n",
      "- Dr. Amanda Foster is a Senior Partner and Healthcare Practice Lead at Meridian Strategic Consulting, with over 14 years of experience and a PhD in Computer Science from Carnegie Mellon.\n",
      "- She has deep expertise in artificial intelligence, machine learning, and healthcare analytics, including leading predictive analytics projects for patient outcomes and implementing AI-powered diagnostic tools in healthcare settings.\n",
      "- She is an expert in both technology and healthcare, having worked with 15 healthcare systems and 8 pharmaceutical companies.\n",
      "- Achievements include: Led AI implementations generating $500M+ in client value, implemented AI-powered diagnostic tools increasing accuracy by 23%, and optimized electronic health records (EHR).\n",
      "- Dr. Foster’s recent projects and leadership roles demonstrate hands-on experience in healthcare AI/ML engagement.\n",
      "- Contact: amanda.foster@meridianstrategic.com\n",
      "- Availability: Available for new engagements starting February 2025. For a project needing to start after this date, she’s an ideal fit.\n",
      "\n",
      "If your timeline aligns with her availability, Dr. Amanda Foster would be the top recommendation for your project requirements. Should you need someone to start sooner, Sarah Chen also has expertise in healthcare and advanced AI/ML capabilities, and could be considered as an alternative.\n",
      "\n",
      "Let me know if you’d like detailed profiles or introductions for either consultant.\n"
     ]
    }
   ],
   "source": [
    "thread = agent.get_new_thread()\n",
    "\n",
    "query = \"I need a consultant with AI/ML expertise and healthcare industry experience for a 6-month project. Who would be the best match?\" \n",
    "response = await agent.run(query, thread=thread)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c29b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Evaluator model\n",
    "from azure.ai.evaluation import  AzureOpenAIModelConfiguration\n",
    "evaluator_model = AzureOpenAIModelConfiguration({\n",
    "    \"type\":\"azure_openai\",\n",
    "    \"azure_deployment\": \"gpt-4.1\",\n",
    "    \"azure_endpoint\": config.azure_openai_endpoint,\n",
    "    \"api_key\": config.credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6cccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-05 19:35:59 - f:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_common\\_experimental.py:79 - WARNING] Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "[2025-10-05 19:35:59 - f:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_common\\utils.py:575 - WARNING] Conversation history could not be parsed, falling back to original query: I need a consultant with AI/ML expertise and healthcare industry experience for a 6-month project. Who would be the best match?\n",
      "[2025-10-05 19:35:59 - f:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_common\\utils.py:629 - WARNING] Empty agent response extracted, likely due to input schema change. Falling back to using the original response: Based on your requirements for a consultant with AI/ML expertise and healthcare industry experience for a 6-month project, Dr. Amanda Foster would be the best match.\n",
      "\n",
      "Context from the knowledge base:\n",
      "\n",
      "- Dr. Amanda Foster is a Senior Partner and Healthcare Practice Lead at Meridian Strategic Consulting, with over 14 years of experience and a PhD in Computer Science from Carnegie Mellon.\n",
      "- She has deep expertise in artificial intelligence, machine learning, and healthcare analytics, including leading predictive analytics projects for patient outcomes and implementing AI-powered diagnostic tools in healthcare settings.\n",
      "- She is an expert in both technology and healthcare, having worked with 15 healthcare systems and 8 pharmaceutical companies.\n",
      "- Achievements include: Led AI implementations generating $500M+ in client value, implemented AI-powered diagnostic tools increasing accuracy by 23%, and optimized electronic health records (EHR).\n",
      "- Dr. Foster’s recent projects and leadership roles demonstrate hands-on experience in healthcare AI/ML engagement.\n",
      "- Contact: amanda.foster@meridianstrategic.com\n",
      "- Availability: Available for new engagements starting February 2025. For a project needing to start after this date, she’s an ideal fit.\n",
      "\n",
      "If your timeline aligns with her availability, Dr. Amanda Foster would be the top recommendation for your project requirements. Should you need someone to start sooner, Sarah Chen also has expertise in healthcare and advanced AI/ML capabilities, and could be considered as an alternative.\n",
      "\n",
      "Let me know if you’d like detailed profiles or introductions for either consultant.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'intent_resolution': 3.0,\n",
       " 'intent_resolution_result': 'pass',\n",
       " 'intent_resolution_threshold': 3,\n",
       " 'intent_resolution_reason': 'The user wanted the best consultant match for a 6-month AI/ML healthcare project. The agent named Dr. Amanda Foster as the best match but omitted her unavailability until February 2025, which is a critical detail for project fit. This notable omission limits resolution.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showcase Intent Resolution Evaluator\n",
    "from azure.ai.evaluation import IntentResolutionEvaluator\n",
    "\n",
    "intres_evaluator = IntentResolutionEvaluator(\n",
    "    model_config=evaluator_model,\n",
    "    credential=credential)\n",
    "\n",
    "intres_evaluator(query=query, response=response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4312a496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'groundedness': 4.0,\n",
       " 'gpt_groundedness': 4.0,\n",
       " 'groundedness_reason': 'The RESPONSE correctly identifies Dr. Amanda Foster as a strong match based on expertise, but omits key context about her availability and the alternative consultant, making it incomplete.',\n",
       " 'groundedness_result': 'pass',\n",
       " 'groundedness_threshold': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showcase Groundedness Evaluator\n",
    "from azure.ai.evaluation import GroundednessEvaluator\n",
    "\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config=evaluator_model, credential=credential)\n",
    "groundedness_evaluator(\n",
    "    query=query, \n",
    "    response=response.text,\n",
    "    context=\"Dr. Amanda foster is a data scientist with 10 years of experience in the healthcare industry. She has worked on multiple AI/ML projects and has expertise in machine learning, data analysis, and statistical modeling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008f723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg@3': 1.0,\n",
       " 'xdcg@3': 120.40816326530613,\n",
       " 'fidelity': 1.0,\n",
       " 'top1_relevance': 5,\n",
       " 'top3_max_relevance': 5,\n",
       " 'holes': 1,\n",
       " 'holes_ratio': 0.16666666666666666,\n",
       " 'total_retrieved_documents': 6,\n",
       " 'total_ground_truth_documents': 6,\n",
       " 'ndcg@3_result': 'pass',\n",
       " 'ndcg@3_threshold': 0.5,\n",
       " 'ndcg@3_higher_is_better': True,\n",
       " 'xdcg@3_result': 'pass',\n",
       " 'xdcg@3_threshold': 50.0,\n",
       " 'xdcg@3_higher_is_better': True,\n",
       " 'fidelity_result': 'pass',\n",
       " 'fidelity_threshold': 0.5,\n",
       " 'fidelity_higher_is_better': True,\n",
       " 'top1_relevance_result': 'fail',\n",
       " 'top1_relevance_threshold': 50.0,\n",
       " 'top1_relevance_higher_is_better': True,\n",
       " 'top3_max_relevance_result': 'fail',\n",
       " 'top3_max_relevance_threshold': 50.0,\n",
       " 'top3_max_relevance_higher_is_better': True,\n",
       " 'holes_result': 'fail',\n",
       " 'holes_threshold': 0,\n",
       " 'holes_higher_is_better': False,\n",
       " 'holes_ratio_result': 'fail',\n",
       " 'holes_ratio_threshold': 0,\n",
       " 'holes_ratio_higher_is_better': False,\n",
       " 'total_retrieved_documents_result': 'fail',\n",
       " 'total_retrieved_documents_threshold': 50,\n",
       " 'total_retrieved_documents_higher_is_better': True,\n",
       " 'total_ground_truth_documents_result': 'fail',\n",
       " 'total_ground_truth_documents_threshold': 50,\n",
       " 'total_ground_truth_documents_higher_is_better': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Document Retrieval \n",
    "from azure.ai.evaluation import DocumentRetrievalEvaluator, AIAgentConverter\n",
    "\n",
    "# Represents the ideal documents that should be retrieved for the given query, with relevance labels from 0 (not relevant) to 5 (highly relevant)\n",
    "retrieval_ground_truth = [\n",
    "    {\n",
    "        \"document_id\": \"people-expertise/expert-profiles.md\",\n",
    "        \"query_relevance_label\": 5,  \n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"people-expertise/skills-matrix.md\",\n",
    "        \"query_relevance_label\": 5,  \n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"core-business/industry-expertise.md\", \n",
    "        \"query_relevance_label\": 4\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"core-business/service-offerings.md\",\n",
    "        \"query_relevance_label\": 3 \n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"market-intelligence/industry-trends-q4-2024.md\",\n",
    "        \"query_relevance_label\": 1\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"sales-proposals/proposal-templates.md\",\n",
    "        \"query_relevance_label\": 0\n",
    "   }\n",
    "]\n",
    "\n",
    "# Represents what was actually retrieved from the search index by the Agent\n",
    "retrieved_documents = [\n",
    "    {\n",
    "        \"document_id\": \"people-expertise/skills-matrix.md\",\n",
    "        \"relevance_score\": 2.395587682723999\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"people-expertise/expert-profiles.md\",\n",
    "        \"relevance_score\": 2.332935094833374\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"core-business/industry-expertise.md\",\n",
    "        \"relevance_score\": 2.2740046977996826\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"core-business/service-offerings.md\",\n",
    "        \"relevance_score\": 2.2369625568389893\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"market-intelligence/industry-trends-q4-2024.md\",\n",
    "        \"relevance_score\": 2.2054591178894043\n",
    "    },\n",
    "    {\n",
    "        \"document_id\": \"market-intelligence/competitive-analysis.md\",\n",
    "        \"relevance_score\": 2.0840091705322266\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "document_retrieval_evaluator = DocumentRetrievalEvaluator(\n",
    "    ground_truth_label_max=5,\n",
    "    ground_truth_label_min=0,\n",
    ")\n",
    "\n",
    "document_retrieval_evaluator(retrieval_ground_truth=retrieval_ground_truth,\n",
    "                             retrieved_documents=retrieved_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e38ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-05 19:42:42 +0200   43332 execution.bulk     INFO     Finished 20 / 20 lines.\n",
      "2025-10-05 19:42:42 +0200   43332 execution.bulk     INFO     Average execution time for completed lines: 2.26 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-05 19:42:42 - f:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\evaluation\\_evaluate\\_batch_run\\_run_submitter_client.py:143 - WARNING] Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"qa_20251005_174157_219134\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-05 17:41:57.219134+00:00\"\n",
      "Duration: \"0:00:45.264662\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation on a batch of data\n",
    "from azure.ai.evaluation import evaluate, QAEvaluator, ContentSafetyEvaluator, AzureAIProject\n",
    "\n",
    "result = evaluate(\n",
    "    data = \"eval.jsonl\",\n",
    "    evaluators = {\n",
    "        \"qa\": QAEvaluator(\n",
    "            model_config=evaluator_model, \n",
    "            credential=credential, \n",
    "            azure_ai_project=config.foundry_project_endpoint),\n",
    "        \"content_safety\": ContentSafetyEvaluator(\n",
    "            credential=credential,\n",
    "            azure_ai_project=config.foundry_project_endpoint)\n",
    "    },\n",
    "    output_path=\"./eval.ouputs.json\",\n",
    "    azure_ai_project=AzureAIProject({\n",
    "        \"subscription_id\":config.subscription_id, \n",
    "        \"resource_group_name\":config.resource_group_name, \n",
    "        \"project_name\": config.foundry_project_name}),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4388dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceNotFoundError",
     "evalue": "(None) No thread found with id 'thread_Krk4b9vK1QRoYXOIfHxUWh8w'.\nCode: None\nMessage: No thread found with id 'thread_Krk4b9vK1QRoYXOIfHxUWh8w'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:64\u001b[39m, in \u001b[36mAsyncList.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mStopIteration\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mStopAsyncIteration\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:148\u001b[39m, in \u001b[36mAsyncItemPaged.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._page.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:66\u001b[39m, in \u001b[36mAsyncList.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m() \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mStopAsyncIteration\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mResourceNotFoundError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cleanup\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# delete all threads\u001b[39;00m\n\u001b[32m      4\u001b[39m threads = agent_client.project_client.agents.threads.list()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m agent_client.project_client.agents.threads.delete(thread_id=t.id)\n\u001b[32m      8\u001b[39m agents = agent_client.project_client.agents.list_agents()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:151\u001b[39m, in \u001b[36mAsyncItemPaged.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m._page = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__anext__\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:145\u001b[39m, in \u001b[36mAsyncItemPaged.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# Let it raise StopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28mself\u001b[39m._page = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._page_iterator.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__anext__\u001b[39m()\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\async_paging.py:94\u001b[39m, in \u001b[36mAsyncPageIterator.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mEnd of paging\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28mself\u001b[39m._response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_next(\u001b[38;5;28mself\u001b[39m.continuation_token)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error.continuation_token:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\ai\\agents\\aio\\operations\\_operations.py:341\u001b[39m, in \u001b[36mThreadsOperations.list.<locals>.get_next\u001b[39m\u001b[34m(_continuation_token)\u001b[39m\n\u001b[32m    338\u001b[39m response = pipeline_response.http_response\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m200\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     \u001b[43mmap_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     error = _failsafe_deserialize(_models.AgentV1Error, response)\n\u001b[32m    343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=response, model=error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\repo\\evaluation-intro\\.venv\\Lib\\site-packages\\azure\\core\\exceptions.py:163\u001b[39m, in \u001b[36mmap_error\u001b[39m\u001b[34m(status_code, response, error_map)\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    162\u001b[39m error = error_type(response=response)\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[31mResourceNotFoundError\u001b[39m: (None) No thread found with id 'thread_Krk4b9vK1QRoYXOIfHxUWh8w'.\nCode: None\nMessage: No thread found with id 'thread_Krk4b9vK1QRoYXOIfHxUWh8w'."
     ]
    }
   ],
   "source": [
    "# Cleanup\n",
    "\n",
    "# delete all threads\n",
    "threads = agent_client.project_client.agents.threads.list()\n",
    "async for t in threads:\n",
    "    await agent_client.project_client.agents.threads.delete(thread_id=t.id)\n",
    "\n",
    "agents = agent_client.project_client.agents.list_agents()\n",
    "async for a in agents:\n",
    "    await agent_client.project_client.agents.delete_agent(agent_id=a.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94724c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a177c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "\n",
    "# delete all threads\n",
    "threads = agent_client.project_client.agents.threads.list()\n",
    "async for t in threads:\n",
    "    await agent_client.project_client.agents.threads.delete(thread_id=t.id)\n",
    "\n",
    "agents = agent_client.project_client.agents.list_agents()\n",
    "async for a in agents:\n",
    "    await agent_client.project_client.agents.delete_agent(agent_id=a.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation-intro (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
